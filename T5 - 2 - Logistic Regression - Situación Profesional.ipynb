{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwT8LAD0H-kt"
      },
      "source": [
        "# Implementación el método de la máxima verosimilitud para la regresión logística\n",
        "\n",
        "#### Fuente:\n",
        "https://www.cienciadedatos.net/documentos/py17-regresion-logistica-python.html\n",
        "\n",
        "https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple\n",
        "\n",
        "\n",
        "\n",
        "#### Otras fuentes:\n",
        "https://medium.com/codex/logistic-regression-and-maximum-likelihood-estimation-function-5d8d998245f9\n",
        "\n",
        "https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/\n",
        "\n",
        "\n",
        "#### Maximum Likelihood Estimation / Estimador de máxima verosimilitud\n",
        "https://faculty.washington.edu/ezivot/econ583/mleLectures.pdf\n",
        "\n",
        "\n",
        "#### Statmodel\n",
        "https://www.statsmodels.org/stable/discretemod.html\n",
        "\n",
        "\n",
        "#### Sklearn\n",
        "https://scikit-learn.org/0.16/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "\n",
        "\n",
        "Para tratar \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4uFVJr_H-ku"
      },
      "source": [
        "## Situación profesional Logistic Regression\n",
        "\n",
        "Resolver las siguientes consignas:\n",
        "\n",
        "1- Indicar la secuencia de pasos para resolver el algoritmo de regresión logística\n",
        "\n",
        "2- La fórmula de la celda 1 ¿Es correcta? ¿Se corresponde con la función likelihood?\n",
        "Revisar el anexo 2: https://www.cienciadedatos.net/documentos/py17-regresion-logistica-python.html\n",
        "\n",
        "3- Modificar la matriz X e Y de la siguientes maneras (resolver con los 3 métodos:\n",
        "    a- Simétricos los 0 y 1 de Y. Aquí aparecerá el mensaje de Sigular matrix https://stackoverflow.com/questions/13795682/numpy-error-singular-matrix \n",
        "    b- dejar un 1 y nueve 0\n",
        "    c- repetir valores en X con distintos valores en Y (ej. x1=1 y1=0, x2=1 y2=1 ....) identificar que pasa con la precisión?. Aplicar otras métricas.\n",
        "  \n",
        "4- Agregar a X atributos (columnas) de manera que queden en total 3. Deben tener valores extremos. \n",
        "\n",
        "5- En el caso del algoritmo codificado con funciones ¿Cómo se realiza una predicción? \n",
        "\n",
        "6- Agregar LogisticRegression de Sklearn y resolver los puntos anteriores.\n",
        "\n",
        "7- Investigar en ésta librería los métodos de ajuste de éste algoritmo ¿Cual método de ajuste usa el código cón funciones?\n",
        "\n",
        "8- Identificar la zona de división de las categorías (esto es sobre valores del eje x, por ej, si para y=0 el máxomo valor es 3 y para y=1 el menor valor es 7) ¿Cual es el máximo para x de y=0 y el mínimo de x para y=1?\n",
        "\n",
        "9- Repetir para 3 categorías, o sea: Y=1, Y=2 e Y=3.\n",
        "\n",
        "10- Emitir un informe.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RESPUESTAS\n",
        "\n",
        "1- Indicar la secuencia de pasos para resolver el algoritmo de regresión logística\n",
        "\n",
        "  Las etapas para resolver el algoritmo de regresion logistica son los siguientes:\n",
        "\n",
        "\n",
        "  1.   Importar conjunto de datos.\n",
        "  2.   Importar Librerias.\n",
        "  3.   Análisis exploratorio de datos\n",
        "    1. a - Listar columnas.\n",
        "    2. b - Numero de Observaciones.\n",
        "    3. c - Tipos de datos de las columnas.\n",
        "    4. d - Separar entre tipos de Variables (Categoricas, Numericas)\n",
        "    5. e - Valores faltantes en variables categóricas.\n",
        "    6. f - Recuentos / Distribucion / Cardinalidad / de frecuencia de las variables categóricas.\n",
        "    7. g - Normalizacion / Eliminar NAN\n",
        "    8. h - Valores perdidos en **variables numéricas**\n",
        "    9. i - Valores atípicos en **variables numéricas**\n",
        "    10. j - Comprobar la distribución de variables. (graficos).\n",
        "  4. Declarar vector de características y variable de destino\n",
        "  5. Divida los datos en conjuntos de prueba y entrenamiento separados\n",
        "  6. **Instanciar Modelo**\n",
        "  7. Entrenar.\n",
        "  8. Predecir.\n",
        "  9. Evaluar Resultados. (METRICAS)\n",
        "  10. Evaluar Supuestos para corregir y volver a entrenar y Predecir\n",
        "\n",
        "2- La fórmula de la celda 1 ¿Es correcta? ¿Se corresponde con la función likelihood? Revisar el anexo 2: https://www.cienciadedatos.net/documentos/py17-regresion-logistica-python.html\n",
        "\n",
        "R: **SI ES CORRECTA**\n",
        "\n",
        "3- Modificar la matriz X e Y de la siguientes maneras (resolver con los 3 métodos: \n",
        "* a- Simétricos los 0 y 1 de Y. Aquí aparecerá el mensaje de Sigular matrix https://stackoverflow.com/questions/13795682/numpy-error-singular-matrix \n",
        "* b- dejar un 1 y nueve 0 \n",
        "* c- repetir valores en X con distintos valores en Y (ej. x1=1 y1=0, x2=1 y2=1 ....) identificar que pasa con la precisión?. Aplicar otras métricas.\n",
        "\n",
        "La metricas cambian, esto se debe a la disposicion de los tatos, ya que al modificar la matriz Y (salida) al momento de entrenar nuevamente el modelo modifica sustancialmente las metricas.\n",
        "Lo mismo Sucede al modificar la matriz de input (X) ya que las variables cambian sus valores modificando las metricas del modelo.\n",
        "**Si los datos modificados NO CUMPLE con los supuestos de la regresion logistica el modelo no podra correr**\n",
        "\n",
        "\n",
        "4- Agregar a X atributos (columnas) de manera que queden en total 3. Deben tener valores extremos.\n",
        "\n",
        "```\n",
        "xa = np.random.uniform(low=8, high=10, size=10).reshape(10,1)\n",
        "\n",
        "xb = np.random.uniform(low=0, high=3, size=10).reshape(10,1)\n",
        "\n",
        "X_new = np.append(X,xa,axis=1)\n",
        "\n",
        "X_new = np.append(X_new,xb,axis=1)\n",
        "\n",
        "```\n",
        "\n",
        "5- En el caso del algoritmo codificado con funciones ¿Cómo se realiza una predicción?\n",
        "\n",
        "**R: Se le pasa a la funcion 2 parametros.** ¿?\n",
        "\n",
        "6- Agregar LogisticRegression de Sklearn y resolver los puntos anteriores.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# INSTANCIO LIBRERIA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split \n",
        "# split DF\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y_out,test_size=0.2)\n",
        "\n",
        "# instantiate the model\n",
        "logreg = LogisticRegression(solver='newton-cg', random_state=0) # OBTENGO Model \n",
        "# fit the model\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# ESTA ES LA PREDICCION\n",
        "y_pred_test = logreg.predict(X_test)\n",
        "\n",
        "y_pred_test\n",
        "\n",
        "# CALCULO LA PRESICION DEL ALGORITMO DE PREDICCION COMPARANDO EL Y DE SALIDA REAL VS LA PREDICCION\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n",
        "```\n",
        "\n",
        "7- Investigar en ésta librería los métodos de ajuste de éste algoritmo ¿Cual método de ajuste usa el código cón funciones?\n",
        "\n",
        "El metodo de ajuste en la regresion lineal de sklearn se define en el parametro\n",
        "\n",
        "**solver** : {‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’} ,  default=’lbfgs’\n",
        "\n",
        "* Para conjuntos de datos pequeños, 'liblinear' es una buena opción, mientras que 'sag' y 'saga' son más rápidos para conjuntos grandes;\n",
        "\n",
        "* Para problemas multiclase, solo 'newton-cg', 'sag', 'saga' y 'lbfgs' manejan la pérdida multinomial;\n",
        "\n",
        "* 'liblinear' se limita a esquemas de uno contra el resto.\n",
        "\n",
        "**Nota:** La convergencia rápida **'sag' y 'saga'** solo está garantizada en características con aproximadamente la misma escala. Puede preprocesar los datos con un escalador de sklearn.preprocessing.\n",
        "\n",
        "Doc: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "R: El modelo codeado responde al ajuste de liblinear ya que va de 1 variable contra el resto de variables.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vVRxWQc6Jw-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_phc9gScH-kv"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziws4qYEH-kv"
      },
      "source": [
        "### Definir la función de entorno L(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "psWKhsPFH-kw",
        "outputId": "ffe7aae8-288d-4c99-a988-a7c66eae8700"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$$L(\\beta)=\\sum_{i=1}^n P_i^{y_i}(1-Pi)^{y_i}$$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import display, Math, Latex\n",
        "display(Math(r'L(\\beta)=\\sum_{i=1}^n P_i^{y_i}(1-Pi)^{y_i}'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cn009GXNH-kx"
      },
      "outputs": [],
      "source": [
        "def likelihood(y, pi):\n",
        "    import numpy as np\n",
        "    total_sum = 1\n",
        "    sum_in = list(range(1, len(y)+1))\n",
        "    for i in range(len(y)):\n",
        "        sum_in[i] = np.where(y[i]==1, pi[i], 1-pi[i])\n",
        "        total_sum = total_sum * sum_in[i]\n",
        "    return total_sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygWC5cupH-kx"
      },
      "source": [
        "### Calcular las probabilidades para cada observación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "QlZsHVN4H-kx",
        "outputId": "34649305-9f79-4c4e-e446-af19ac63cb27"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$$P_i = P(x_i) = \\frac{1}{1+e^{-\\sum_{j=0}^k\\beta_j\\cdot x_{ij}}} $$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Math(r'P_i = P(x_i) = \\frac{1}{1+e^{-\\sum_{j=0}^k\\beta_j\\cdot x_{ij}}} '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zwJXCXZSH-ky"
      },
      "outputs": [],
      "source": [
        "def logitprobs(X,beta):\n",
        "    import numpy as np\n",
        "    n_rows = np.shape(X)[0]\n",
        "    n_cols = np.shape(X)[1]\n",
        "    pi=list(range(1,n_rows+1))\n",
        "    expon=list(range(1,n_rows+1))\n",
        "    for i in range(n_rows):\n",
        "        expon[i] = 0\n",
        "        for j in range(n_cols):\n",
        "            ex=X[i][j] * beta[j]\n",
        "            expon[i] = ex + expon[i]\n",
        "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "            pi[i]=1/(1+np.exp(-expon[i]))\n",
        "    return pi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDU3pXpJH-ky"
      },
      "source": [
        "### Calcular la matriz diagonal W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "BDLIqVngH-kz",
        "outputId": "dced5739-7d4a-49d0-8056-278af8bb4d56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$$W= diag(P_i \\cdot (1-P_i))_{i=1}^n$$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Math(r'W= diag(P_i \\cdot (1-P_i))_{i=1}^n'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tGEAgDgJH-kz"
      },
      "outputs": [],
      "source": [
        "def findW(pi):\n",
        "    import numpy as np\n",
        "    n = len(pi)\n",
        "    W = np.zeros(n*n).reshape(n,n)\n",
        "    for i in range(n):\n",
        "        print(i)\n",
        "        W[i,i]=pi[i]*(1-pi[i])\n",
        "        W[i,i].astype(float)\n",
        "    return W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSXvePdDH-kz"
      },
      "source": [
        "### Obtener la solución de la función logística"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "bm6baq-AH-kz",
        "outputId": "b7376714-ea21-4e4e-cbae-a8dcc9bd1cb8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$$\\beta_{n+1} = \\beta_n -\\frac{f(\\beta_n)}{f'(\\beta_n)}$$"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$$f(\\beta) = X(Y-P)$$"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Math object>"
            ],
            "text/latex": "$$f'(\\beta) = XWX^T$$"
          },
          "metadata": {}
        }
      ],
      "source": [
        "display(Math(r\"\\beta_{n+1} = \\beta_n -\\frac{f(\\beta_n)}{f'(\\beta_n)}\"))\n",
        "display(Math(r\"f(\\beta) = X(Y-P)\"))\n",
        "display(Math(r\"f'(\\beta) = XWX^T\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sjg_gILQH-k0"
      },
      "outputs": [],
      "source": [
        "def logistics(X, Y, limit):\n",
        "    import numpy as np\n",
        "    from numpy import linalg\n",
        "    nrow = np.shape(X)[0]\n",
        "    bias = np.ones(nrow).reshape(nrow,1)\n",
        "    X_new = np.append(X, bias, axis = 1)\n",
        "    ncol = np.shape(X_new)[1]\n",
        "    beta = np.zeros(ncol).reshape(ncol,1)\n",
        "    root_dif = np.array(range(1,ncol+1)).reshape(ncol,1)\n",
        "    iter_i = 10000\n",
        "    while(iter_i>limit):\n",
        "        print(\"Iter:i\"+str(iter_i) + \", limit:\" + str(limit))\n",
        "        pi = logitprobs(X_new, beta)\n",
        "        print(\"Pi:\"+str(pi))\n",
        "        W = findW(pi)\n",
        "        print(\"W:\"+str(W))\n",
        "        num = (np.transpose(np.matrix(X_new))*np.matrix(Y - np.transpose(pi)).transpose())\n",
        "        den = (np.matrix(np.transpose(X_new))*np.matrix(W)*np.matrix(X_new))\n",
        "        root_dif = np.array(linalg.inv(den)*num)\n",
        "        beta = beta + root_dif\n",
        "        print(\"Beta: \"+str(beta))\n",
        "        iter_i = np.sum(root_dif*root_dif)\n",
        "        ll = likelihood(Y, pi)\n",
        "    return beta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhkSWQ0BH-k0"
      },
      "source": [
        "## Comprobación experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Wv5d-W5xH-k0"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Q_U51hbyH-k0"
      },
      "outputs": [],
      "source": [
        "X = np.array(range(10)).reshape(10,1)\n",
        "#X= np.append(X,X,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLaazDXTH-k1",
        "outputId": "f517bf4b-a813-426f-c0d4-8bf2db7e7001"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [4],\n",
              "       [5],\n",
              "       [6],\n",
              "       [7],\n",
              "       [8],\n",
              "       [9]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "7b99cMgeH-k1"
      },
      "outputs": [],
      "source": [
        "# Y = [0,0,0,0,1,0,1,0,1,1]\n",
        "# Y = [0,0,0,0,0,0,0,0,0,1]\n",
        "Y = [0,0,0,0,0,1,1,1,1,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "LKFWNeYnH-k1"
      },
      "outputs": [],
      "source": [
        "bias = np.ones(10).reshape(10,1)\n",
        "X_new = np.append(X,bias,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaBUVs92H-k1",
        "outputId": "f06667d0-3843-46c3-d28a-5a07f4d69a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 1.],\n",
              "       [2., 1.],\n",
              "       [3., 1.],\n",
              "       [4., 1.],\n",
              "       [5., 1.],\n",
              "       [6., 1.],\n",
              "       [7., 1.],\n",
              "       [8., 1.],\n",
              "       [9., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# AGREGO COLUMNAS EXTREMAS\n",
        "\n",
        "# xa = np.random.uniform(low=8, high=10, size=10).reshape(10,1)\n",
        "# xb = np.random.uniform(low=0, high=3, size=10).reshape(10,1)\n",
        "# X_new = np.append(X,xa,axis=1)\n",
        "# X_new = np.append(X_new,xb,axis=1)\n",
        "\n",
        "X_new"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_9ePt0qH-k1"
      },
      "outputs": [],
      "source": [
        "a = logistics(X,Y,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1FAaUxKZH-k2"
      },
      "outputs": [],
      "source": [
        "ll = likelihood(Y, logitprobs(X,a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fTubjVZH-k2",
        "outputId": "5b93ab2a-812f-42cf-c9a0-906326fb63a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "ll"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "xHnbZ8RLH-k2"
      },
      "outputs": [],
      "source": [
        "Y = 74.10217253 * X -334.45977638"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BjiUF4BH-k2"
      },
      "source": [
        "# Con el paquete statsmodel de python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLKRm6TyH-k2"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "from pandas import Timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi9QcKkYH-k2"
      },
      "outputs": [],
      "source": [
        "Y = (Y - np.min(Y))/np.ptp(Y)\n",
        "logit_model = sm.Logit(Y,X_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSZf-qihH-k2",
        "outputId": "2db8b330-20b4-4524-e53c-682b02e41cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.359693\n",
            "         Iterations 6\n"
          ]
        }
      ],
      "source": [
        "result = logit_model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NVJZtQ-H-k3",
        "outputId": "2bcd17c8-42b2-435d-815b-c1924a065e08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                         Results: Logit\n",
            "================================================================\n",
            "Model:              Logit            Pseudo R-squared: 0.481    \n",
            "Dependent Variable: y                AIC:              11.1939  \n",
            "Date:               2022-02-26 11:26 BIC:              11.7990  \n",
            "No. Observations:   10               Log-Likelihood:   -3.5969  \n",
            "Df Model:           1                LL-Null:          -6.9315  \n",
            "Df Residuals:       8                LLR p-value:      0.0098099\n",
            "Converged:          1.0000           Scale:            1.0000   \n",
            "No. Iterations:     6.0000                                      \n",
            "------------------------------------------------------------------\n",
            "           Coef.    Std.Err.      z      P>|z|     [0.025   0.975]\n",
            "------------------------------------------------------------------\n",
            "x1         0.6272     0.3735    1.6793   0.0931   -0.1048   1.3592\n",
            "const     -2.8224     1.8730   -1.5069   0.1318   -6.4934   0.8485\n",
            "================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(result.summary2())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "wYEcYUSMH-k3"
      },
      "outputs": [],
      "source": [
        "# 6- Agregar LogisticRegression de Sklearn y resolver los puntos anteriores.\n",
        "Y_out = [0,0,0,0,0,1,1,1,1,1]\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y_out,test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the model\n",
        "logreg = LogisticRegression(solver='newton-cg', random_state=0) # OBTENGO Model accuracy score: 0.9500 Confusion matrix\n",
        "# fit the model\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "# ESTA ES LA PREDICCION\n",
        "y_pred_test = logreg.predict(X_test)\n",
        "\n",
        "y_pred_test\n",
        "\n",
        "# CALCULO LA PRESICION DEL ALGORITMO DE PREDICCION COMPARANDO EL Y DE SALIDA REAL VS LA PREDICCION\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
      ],
      "metadata": {
        "id": "yXeLAX72cW68",
        "outputId": "abe6a4d9-c380-46b5-a089-d4a196d027b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy score: 1.0000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "T5 - 2 - Logistic Regression - Situación Profesional.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}